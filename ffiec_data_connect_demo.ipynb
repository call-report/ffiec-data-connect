{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFIEC Data Connect - Comprehensive Demo\n",
    "\n",
    "This notebook demonstrates all the capabilities of the FFIEC Data Connect library, including:\n",
    "- Basic data collection (sync)\n",
    "- Async data collection with rate limiting\n",
    "- Parallel processing for multiple data requests\n",
    "- Working with pandas and polars DataFrames\n",
    "- Error handling and validation\n",
    "- Performance comparisons\n",
    "\n",
    "**Note**: You'll need valid FFIEC credentials to run the live data examples. Mock examples are provided for demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# FFIEC Data Connect - Comprehensive Demo\n\nThis notebook demonstrates all the capabilities of the FFIEC Data Connect library, including:\n- Basic data collection (sync)\n- Async data collection with rate limiting\n- Parallel processing for multiple data requests\n- Working with pandas and polars DataFrames\n- Error handling and validation\n- Performance comparisons\n\n## üöÄ Quick Start\n\n1. **First**: Run the installation cell above to install all required packages\n2. **Second**: Enter your FFIEC credentials when prompted (or set environment variables)\n3. **Then**: Run all remaining cells to see the full demonstration\n\n## üìã Requirements\n\n- Python 3.8+\n- Valid FFIEC CDR credentials (or demo mode will be used)\n- Internet connection for package installation\n\n**Note**: If you have FFIEC credentials, the notebook will collect real data. Otherwise, it will demonstrate all features using mock data.",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Standard library imports\nimport os\nimport asyncio\nimport time\nimport random\nfrom datetime import datetime, timedelta\nfrom typing import List, Dict, Any\n\n# Third-party imports\nimport pandas as pd\nimport polars as pl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n# FFIEC Data Connect imports\nimport ffiec_data_connect as fdc\nfrom ffiec_data_connect import (\n    WebserviceCredentials,\n    FFIECConnection,\n    AsyncCompatibleClient,\n    RateLimiter,\n    collect_data,\n    collect_reporting_periods,\n    collect_filers_on_reporting_period,\n    CredentialError,\n    ValidationError,\n    NoDataError\n)\n\nprint(f\"FFIEC Data Connect version: {fdc.__version__}\")\nprint(f\"Pandas version: {pd.__version__}\")\nprint(f\"Polars version: {pl.__version__}\")"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create an AsyncCompatibleClient instance\nclient = AsyncCompatibleClient(\n    max_concurrent=3,      # Maximum concurrent requests\n    rate_limit=2.0         # Rate limit: 2 seconds between requests\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Environment variables (recommended for production)\n",
    "# Set these in your environment:\n",
    "# export FFIEC_USERNAME=\"your_username\"\n",
    "# export FFIEC_PASSWORD=\"your_password\"\n",
    "\n",
    "try:\n",
    "    # This will use environment variables if available\n",
    "    credentials = WebserviceCredentials()\n",
    "    print(\"‚úÖ Credentials loaded from environment variables\")\n",
    "    print(f\"Username: {credentials.masked_username}\")\n",
    "    \n",
    "except CredentialError:\n",
    "    print(\"‚ùå No credentials found in environment variables\")\n",
    "    print(\"For live data examples, you'll need to set FFIEC_USERNAME and FFIEC_PASSWORD\")\n",
    "    print(\"Using mock mode for demonstrations...\")\n",
    "    \n",
    "    # Create mock credentials for demo purposes\n",
    "    credentials = WebserviceCredentials(\"demo_user\", \"demo_pass\")\n",
    "    DEMO_MODE = True\n",
    "else:\n",
    "    DEMO_MODE = False\n",
    "\n",
    "# Method 2: Direct instantiation (for testing/development)\n",
    "# credentials = WebserviceCredentials(\"your_username\", \"your_password\")\n",
    "\n",
    "# Method 3: Interactive (uncomment to use)\n",
    "# import getpass\n",
    "# username = input(\"FFIEC Username: \")\n",
    "# password = getpass.getpass(\"FFIEC Password: \")\n",
    "# credentials = WebserviceCredentials(username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîå Connection Management\n",
    "\n",
    "The library provides multiple connection management approaches:\n",
    "- Basic FFIECConnection\n",
    "- AsyncCompatibleClient with advanced features\n",
    "- Context managers for automatic cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Basic connection\nbasic_connection = FFIECConnection()\nprint(f\"Basic connection: {basic_connection}\")\nprint(f\"Session active: {basic_connection.session is not None}\")\n\n# Advanced async-compatible client with rate limiting\nasync_client = AsyncCompatibleClient(\n    credentials=credentials,\n    max_concurrent=4,  # Max 4 concurrent requests\n    rate_limit=0.5  # Max 0.5 requests per second (30 per minute)\n)\n\nprint(f\"\\nAsync client: {async_client}\")\nprint(f\"Rate limiter: {async_client.rate_limiter}\")\n\n# Context manager usage (recommended)\nprint(\"\\nüîÑ Testing context manager...\")\nwith AsyncCompatibleClient(credentials) as client:\n    print(f\"Client active: {len(client._connection_cache) >= 0}\")  # Check cache exists\nprint(\"Client automatically closed after context\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Basic Data Collection (Synchronous)\n",
    "\n",
    "Start with the traditional synchronous API for collecting FFIEC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock server setup for demonstration\n",
    "if DEMO_MODE:\n",
    "    from tests.mocks.soap_server import MockFFIECServer\n",
    "    \n",
    "    # Start mock server for demo\n",
    "    mock_server = MockFFIECServer(host='localhost', port=8089)\n",
    "    mock_server.start()\n",
    "    print(\"üöÄ Mock FFIEC server started for demonstration\")\n",
    "    print(f\"Mock server URL: {mock_server.url}\")\n",
    "    \n",
    "    # Patch the connection to use mock server\n",
    "    import ffiec_data_connect.constants as constants\n",
    "    constants.WebserviceConstants.base_url = mock_server.wsdl_url\n",
    "    \n",
    "    # Sample data for demos\n",
    "    SAMPLE_BANKS = [\"480228\", \"852320\", \"628403\"]  # JPMorgan Chase, Bank of America, Wells Fargo\n",
    "    SAMPLE_PERIODS = [\"2023-12-31\", \"2023-09-30\", \"2023-06-30\"]\n",
    "else:\n",
    "    # Real data examples (you'll need valid credentials)\n",
    "    SAMPLE_BANKS = [\"480228\", \"852320\"]  # Use fewer banks for real API\n",
    "    SAMPLE_PERIODS = [\"2023-12-31\", \"2023-09-30\"]\n",
    "\n",
    "print(f\"Sample banks (RSSD IDs): {SAMPLE_BANKS}\")\n",
    "print(f\"Sample periods: {SAMPLE_PERIODS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get available reporting periods\n",
    "print(\"üìÖ Getting available reporting periods...\")\n",
    "\n",
    "try:\n",
    "    periods = collect_reporting_periods(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        series=\"call\",\n",
    "        output_type=\"list\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Found {len(periods)} reporting periods\")\n",
    "    print(\"Recent periods:\")\n",
    "    for period in periods[:5]:  # Show first 5\n",
    "        print(f\"  - {period}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error getting periods: {e}\")\n",
    "    periods = SAMPLE_PERIODS  # Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Collect data for a single bank\n",
    "print(\"üè¶ Collecting data for a single bank...\")\n",
    "\n",
    "rssd_id = SAMPLE_BANKS[0]  # JPMorgan Chase\n",
    "reporting_period = SAMPLE_PERIODS[0]  # Most recent\n",
    "\n",
    "print(f\"Bank RSSD ID: {rssd_id}\")\n",
    "print(f\"Reporting period: {reporting_period}\")\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    bank_data = collect_data(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        reporting_period=reporting_period,\n",
    "        rssd_id=rssd_id,\n",
    "        series=\"call\",\n",
    "        output_type=\"list\"\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Collected {len(bank_data)} data points in {elapsed:.2f} seconds\")\n",
    "    \n",
    "    # Show sample data\n",
    "    if bank_data:\n",
    "        print(\"\\nSample data points:\")\n",
    "        for i, item in enumerate(bank_data[:3]):\n",
    "            print(f\"  {i+1}. {item}\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error collecting data: {e}\")\n",
    "    bank_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Async Data Collection\n",
    "\n",
    "The AsyncCompatibleClient provides async methods for better performance when collecting multiple datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Async data collection with rate limiting\nasync def collect_data_async_demo():\n    \"\"\"Demo async data collection with rate limiting.\"\"\"\n    \n    # Use async context manager\n    async with AsyncCompatibleClient(\n        credentials=credentials,\n        max_concurrent=5,\n        rate_limit=2.0  # 2 requests per second\n    ) as client:\n        \n        print(\"üöÄ Starting async data collection...\")\n        start_time = time.time()\n        \n        # Collect data for multiple banks async\n        tasks = []\n        for rssd_id in SAMPLE_BANKS[:2]:  # First 2 banks\n            task = client.collect_data_async(\n                reporting_period=SAMPLE_PERIODS[0],\n                rssd_id=rssd_id,\n                series=\"call\"\n            )\n            tasks.append((rssd_id, task))\n        \n        # Wait for all tasks to complete\n        results = []\n        for rssd_id, task in tasks:\n            try:\n                data = await task\n                results.append((rssd_id, data))\n                print(f\"‚úÖ Bank {rssd_id}: {len(data)} data points\")\n            except Exception as e:\n                print(f\"‚ùå Bank {rssd_id}: Error - {e}\")\n        \n        elapsed = time.time() - start_time\n        print(f\"\\n‚è±Ô∏è Async collection completed in {elapsed:.2f} seconds\")\n        return results\n\n# Run the async demo\ntry:\n    async_results = await collect_data_async_demo()\nexcept Exception as e:\n    print(f\"‚ùå Async demo error: {e}\")\n    async_results = []"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Parallel Processing (Sync Interface)\n",
    "\n",
    "For users who prefer synchronous code, the library provides parallel processing with a sync interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Parallel data collection with sync interface\nprint(\"üîÑ Parallel data collection demo...\")\n\nwith AsyncCompatibleClient(credentials, max_concurrent=3) as client:\n    \n    print(f\"Collecting data for multiple banks in parallel...\")\n    \n    # Progress callback function\n    def progress_callback(rssd_id: str, result: Any):\n        if 'error' in str(result):\n            print(f\"‚ùå Bank {rssd_id}: Error\")\n        else:\n            data_points = len(result) if isinstance(result, list) else 0\n            print(f\"‚úÖ Bank {rssd_id}: {data_points} data points\")\n    \n    try:\n        start_time = time.time()\n        \n        # Use parallel collection method with correct signature\n        results = client.collect_data_parallel(\n            reporting_period=SAMPLE_PERIODS[0],  # Single period\n            rssd_ids=SAMPLE_BANKS[:2],  # Multiple banks\n            series='call',\n            progress_callback=progress_callback\n        )\n        \n        elapsed = time.time() - start_time\n        \n        # Process results\n        successful = [r for r in results.values() if 'error' not in str(r)]\n        failed = [r for r in results.values() if 'error' in str(r)]\n        \n        print(f\"\\n‚úÖ Parallel collection completed in {elapsed:.2f} seconds\")\n        print(f\"üìà Successful: {len(successful)}, Failed: {len(failed)}\")\n        \n        if successful:\n            total_data_points = sum(len(r) if isinstance(r, list) else 0 for r in successful)\n            print(f\"üìä Total data points collected: {total_data_points}\")\n            \n    except Exception as e:\n        print(f\"‚ùå Parallel collection error: {e}\")\n        results = {}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Data Type Consistency with Polars\n\nThe library ensures proper numpy dtypes throughout the data pipeline from XBRL processing to pandas DataFrames to polars conversion. Let's convert the pandas DataFrame to polars and examine the type consistency."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Direct XBRL to polars conversion - preserves maximum precision\ntry:\n    df_polars_direct = collect_data(\n        session=basic_connection.session,\n        creds=credentials, \n        reporting_period=\"2023-12-31\",\n        rssd_id=\"480228\",\n        series=\"call\",\n        output_type=\"polars\"  # Direct conversion from XBRL to polars\n    )\n    \n    print(\"Direct XBRL ‚Üí polars DataFrame:\")\n    print(f\"Shape: {df_polars_direct.shape}\")\n    print(f\"Schema: {df_polars_direct.schema}\")\n    print(\"\\nFirst few rows:\")\n    print(df_polars_direct.head())\n    \nexcept Exception as e:\n    print(f\"‚ùå Error creating polars DataFrame: {e}\")\n    # Create empty DataFrame for demo\n    import polars as pl\n    df_polars_direct = pl.DataFrame({\n        'mdrm': ['DEMO'],\n        'rssd': ['480228'], \n        'quarter': ['2023-12-31'],\n        'data_type': ['int'],\n        'int_data': [1000000],\n        'float_data': [None],\n        'bool_data': [None],\n        'str_data': [None]\n    })"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create pandas DataFrame for comparison\ntry:\n    df_pandas = collect_data(\n        session=basic_connection.session,\n        creds=credentials,\n        reporting_period=\"2023-12-31\", \n        rssd_id=\"480228\",\n        series=\"call\",\n        output_type=\"pandas\"  # Standard pandas conversion\n    )\n    \n    print(\"=== Type Precision Comparison ===\")\n    print(\"\\nPandas DataFrame (via pandas conversion):\")\n    print(df_pandas.dtypes)\n    \n    if len(df_pandas) > 0 and 'int_data' in df_pandas.columns:\n        int_samples = df_pandas.dropna(subset=['int_data'])\n        if len(int_samples) > 0:\n            sample_pandas = int_samples['int_data'].iloc[0]\n            print(f\"Sample int value: {sample_pandas} (type: {type(sample_pandas)})\")\n        \n        print(\"\\nPolars DataFrame (direct from XBRL):\")  \n        print(df_polars_direct.schema)\n        \n        if len(df_polars_direct) > 0:\n            polars_ints = df_polars_direct.filter(pl.col('int_data').is_not_null())\n            if len(polars_ints) > 0:\n                sample_polars = polars_ints['int_data'].first()\n                print(f\"Sample int value: {sample_polars} (type: {type(sample_polars)})\")\n                \n                # Verify no precision loss in the direct conversion\n                int_data_polars = polars_ints['int_data'].to_list()\n                int_data_pandas = int_samples['int_data'].tolist()\n                \n                print(f\"\\nPrecision check - values match: {int_data_polars == int_data_pandas}\")\n            \nexcept Exception as e:\n    print(f\"‚ùå Error in comparison: {e}\")\n    # Create demo pandas DataFrame\n    import pandas as pd\n    df_pandas = pd.DataFrame({\n        'mdrm': ['DEMO'],\n        'rssd': ['480228'],\n        'quarter': ['2023-12-31'], \n        'data_type': ['int'],\n        'int_data': [1000000],\n        'float_data': [None],\n        'bool_data': [None],\n        'str_data': [None]\n    })\n    print(\"Using demo data for comparison\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pandas data to various formats\n",
    "print(\"üíæ Saving pandas data to files...\")\n",
    "\n",
    "# Save to CSV\n",
    "csv_file = 'ffiec_data_pandas.csv'\n",
    "df_pandas.to_csv(csv_file, index=False)\n",
    "print(f\"‚úÖ Saved to CSV: {csv_file}\")\n",
    "\n",
    "# Save to Excel\n",
    "excel_file = 'ffiec_data_pandas.xlsx'\n",
    "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "    df_pandas.to_excel(writer, sheet_name='All_Data', index=False)\n",
    "    \n",
    "    # Create separate sheets by metric\n",
    "    if 'metric' in df_pandas.columns:\n",
    "        for metric in df_pandas['metric'].unique():\n",
    "            metric_data = df_pandas[df_pandas['metric'] == metric]\n",
    "            safe_sheet_name = metric.replace(' ', '_')[:31]  # Excel sheet name limits\n",
    "            metric_data.to_excel(writer, sheet_name=safe_sheet_name, index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved to Excel: {excel_file}\")\n",
    "\n",
    "# Save to Parquet (efficient for large datasets)\n",
    "parquet_file = 'ffiec_data_pandas.parquet'\n",
    "df_pandas.to_parquet(parquet_file, index=False)\n",
    "print(f\"‚úÖ Saved to Parquet: {parquet_file}\")\n",
    "\n",
    "# Display file sizes\n",
    "import os\n",
    "print(\"\\nüìè File sizes:\")\n",
    "for file in [csv_file, excel_file, parquet_file]:\n",
    "    if os.path.exists(file):\n",
    "        size_mb = os.path.getsize(file) / (1024 * 1024)\n",
    "        print(f\"  {file}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Display the schemas to verify type consistency\nprint(\"=== Final Schema Comparison ===\")\n\nif 'df_pandas' in locals():\n    print(\"\\nPandas DataFrame dtypes:\")\n    print(df_pandas.dtypes)\nelse:\n    print(\"\\n‚ùå Pandas DataFrame not available\")\n\nif 'df_polars_direct' in locals():\n    print(\"\\nPolars DataFrame schema (direct conversion):\")\n    print(df_polars_direct.schema)\n    \n    # Show some sample data with proper types\n    if len(df_polars_direct) > 0:\n        int_vals = df_polars_direct.filter(pl.col('int_data').is_not_null())\n        float_vals = df_polars_direct.filter(pl.col('float_data').is_not_null())\n        bool_vals = df_polars_direct.filter(pl.col('bool_data').is_not_null())\n        \n        if len(int_vals) > 0:\n            sample_int = int_vals['int_data'].first()\n            print(f\"\\nSample integer value: {sample_int} (type: {type(sample_int)})\")\n            \n        if len(float_vals) > 0:\n            sample_float = float_vals['float_data'].first()\n            print(f\"Sample float value: {sample_float} (type: {type(sample_float)})\")\n            \n        if len(bool_vals) > 0:\n            sample_bool = bool_vals['bool_data'].first()\n            print(f\"Sample boolean value: {sample_bool} (type: {type(sample_bool)})\")\n        else:\n            print(\"\\nNo boolean data in this dataset\")\n            \n    print(f\"\\n‚úÖ Direct polars conversion preserves {len(df_polars_direct.schema)} column types\")\nelse:\n    print(\"\\n‚ùå Polars DataFrame not available\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Polars DataFrame from the same data\n",
    "print(\"‚ö° Creating Polars DataFrame...\")\n",
    "\n",
    "# Convert from pandas or create directly\n",
    "df_polars = pl.from_pandas(df_pandas)\n",
    "\n",
    "# Or create directly from data\n",
    "# df_polars = pl.DataFrame(pandas_data)\n",
    "\n",
    "print(f\"Created Polars DataFrame with {len(df_polars)} rows\")\n",
    "print(f\"Columns: {df_polars.columns}\")\n",
    "print(f\"Schema: {df_polars.schema}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nüìä Sample data (Polars):\")\n",
    "print(df_polars.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Polars data analysis examples\nprint(\"‚ö° Polars Analysis Examples:\")\n\n# Check the actual data structure to provide meaningful analysis\nprint(f\"\\nAvailable columns: {df_polars.columns}\")\nprint(f\"Data types in the data: {df_polars['data_type'].unique().to_list() if 'data_type' in df_polars.columns else 'No data_type column'}\")\n\n# Create meaningful analysis based on the actual data structure\nif len(df_polars) > 0 and 'int_data' in df_polars.columns:\n    \n    # 1. Basic aggregation by data type\n    print(\"\\nüìä Data summary by type:\")\n    type_summary = (\n        df_polars\n        .group_by('data_type')\n        .agg([\n            pl.count().alias('count'),\n            pl.col('mdrm').n_unique().alias('unique_mdrms')\n        ])\n        .sort('data_type')\n    )\n    print(type_summary)\n    \n    # 2. Integer data analysis (if available)\n    int_data = df_polars.filter(pl.col('int_data').is_not_null())\n    if len(int_data) > 0:\n        print(f\"\\nüí∞ Integer data analysis ({len(int_data)} records):\")\n        int_stats = (\n            int_data\n            .group_by(['rssd', 'quarter'])\n            .agg([\n                pl.col('int_data').min().alias('min_value'),\n                pl.col('int_data').max().alias('max_value'),\n                pl.col('int_data').mean().alias('avg_value'),\n                pl.col('int_data').count().alias('count')\n            ])\n            .sort('rssd')\n        )\n        print(int_stats)\n        \n        # Top 5 largest values\n        top_values = (\n            int_data\n            .sort('int_data', descending=True)\n            .select(['mdrm', 'rssd', 'quarter', 'int_data'])\n            .head(5)\n        )\n        print(f\"\\nüèÜ Top 5 largest integer values:\")\n        print(top_values)\n    \n    # 3. Float data analysis (if available)\n    float_data = df_polars.filter(pl.col('float_data').is_not_null())\n    if len(float_data) > 0:\n        print(f\"\\nüìà Float data analysis ({len(float_data)} records):\")\n        float_stats = (\n            float_data\n            .group_by('rssd')\n            .agg([\n                pl.col('float_data').min().alias('min_ratio'),\n                pl.col('float_data').max().alias('max_ratio'),\n                pl.col('float_data').mean().alias('avg_ratio'),\n                pl.col('float_data').count().alias('count')\n            ])\n            .sort('avg_ratio', descending=True)\n        )\n        print(float_stats)\n    \n    # 4. MDRM code frequency analysis\n    print(f\"\\nüìã Most common MDRM codes:\")\n    mdrm_freq = (\n        df_polars\n        .group_by('mdrm')\n        .agg([\n            pl.count().alias('frequency'),\n            pl.col('data_type').first().alias('data_type')\n        ])\n        .sort('frequency', descending=True)\n        .head(10)\n    )\n    print(mdrm_freq)\n    \n    # 5. Data distribution by bank and quarter\n    print(f\"\\nüè¶ Data points by bank and quarter:\")\n    bank_quarter_summary = (\n        df_polars\n        .group_by(['rssd', 'quarter'])\n        .agg([\n            pl.count().alias('total_data_points'),\n            pl.col('data_type').n_unique().alias('unique_data_types')\n        ])\n        .sort(['rssd', 'quarter'])\n    )\n    print(bank_quarter_summary)\n\nelse:\n    print(\"\\nüìù This dataset uses the direct XBRL structure with type-specific columns:\")\n    print(\"   - int_data: Integer financial values\")\n    print(\"   - float_data: Ratio and percentage values\") \n    print(\"   - bool_data: Boolean indicators\")\n    print(\"   - str_data: Text values\")\n    print(\"\\nüí° This design preserves maximum type precision from the XBRL source\")\n    print(\"   and avoids the precision loss that can occur with generic 'value' columns.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Polars data to various formats\n",
    "print(\"üíæ Saving Polars data to files...\")\n",
    "\n",
    "# Polars CSV (very fast)\n",
    "polars_csv = 'ffiec_data_polars.csv'\n",
    "df_polars.write_csv(polars_csv)\n",
    "print(f\"‚úÖ Saved to CSV: {polars_csv}\")\n",
    "\n",
    "# Polars Parquet (recommended for large datasets)\n",
    "polars_parquet = 'ffiec_data_polars.parquet'\n",
    "df_polars.write_parquet(polars_parquet)\n",
    "print(f\"‚úÖ Saved to Parquet: {polars_parquet}\")\n",
    "\n",
    "# JSON (good for smaller datasets)\n",
    "polars_json = 'ffiec_data_polars.json'\n",
    "df_polars.write_json(polars_json)\n",
    "print(f\"‚úÖ Saved to JSON: {polars_json}\")\n",
    "\n",
    "# Delta format (if delta-rs is installed)\n",
    "try:\n",
    "    df_polars.write_delta('ffiec_data_delta')\n",
    "    print(f\"‚úÖ Saved to Delta format\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è Delta format not available: {e}\")\n",
    "\n",
    "# Display file sizes comparison\n",
    "print(\"\\nüìè File sizes comparison:\")\n",
    "polars_files = [polars_csv, polars_parquet, polars_json]\n",
    "for file in polars_files:\n",
    "    if os.path.exists(file):\n",
    "        size_mb = os.path.getsize(file) / (1024 * 1024)\n",
    "        print(f\"  {file}: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Performance Comparison\n",
    "\n",
    "Compare the performance of different approaches for data collection and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Performance comparison of sync vs async vs parallel\nprint(\"üèÅ Performance Comparison\")\n\n# Create test data for meaningful comparison\nPERFORMANCE_BANKS = SAMPLE_BANKS[:3]  # Use first 3 banks for testing\nPERFORMANCE_PERIOD = SAMPLE_PERIODS[0]  # Use most recent period\n\nprint(f\"Testing with {len(PERFORMANCE_BANKS)} banks for period {PERFORMANCE_PERIOD}\")\n\n# Mock the collect_data function for performance testing\ndef mock_collect_data(session, creds, reporting_period, rssd_id, series=\"call\", **kwargs):\n    \"\"\"Mock function that simulates data collection delay.\"\"\"\n    import random\n    import time\n    \n    # Simulate network delay\n    time.sleep(random.uniform(0.1, 0.3))\n    \n    # Return mock data\n    return [{\n        'rssd_id': rssd_id,\n        'reporting_period': reporting_period,\n        'metric': 'Total Assets',\n        'value': random.randint(10000, 500000),\n        'mdrm': 'RCON2170'\n    }]\n\nperformance_results = {}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 1: Sequential (traditional approach)\nprint(\"üêå Testing sequential collection...\")\n\nstart_time = time.time()\nsequential_results = []\n\nfor i, rssd_id in enumerate(PERFORMANCE_BANKS):\n    if DEMO_MODE:\n        result = mock_collect_data(\n            session=basic_connection.session,\n            creds=credentials,\n            reporting_period=PERFORMANCE_PERIOD,\n            rssd_id=rssd_id,\n            series=\"call\"\n        )\n    else:\n        try:\n            result = collect_data(\n                session=basic_connection.session,\n                creds=credentials,\n                reporting_period=PERFORMANCE_PERIOD,\n                rssd_id=rssd_id,\n                series=\"call\"\n            )\n        except Exception:\n            result = mock_collect_data(\n                session=basic_connection.session,\n                creds=credentials,\n                reporting_period=PERFORMANCE_PERIOD,\n                rssd_id=rssd_id,\n                series=\"call\"\n            )\n    \n    sequential_results.append(result)\n    print(f\"  Completed {i+1}/{len(PERFORMANCE_BANKS)}\")\n\nsequential_time = time.time() - start_time\nperformance_results['Sequential'] = sequential_time\n\nprint(f\"‚úÖ Sequential: {sequential_time:.2f} seconds for {len(PERFORMANCE_BANKS)} requests\")\nprint(f\"   Average: {sequential_time/len(PERFORMANCE_BANKS):.2f} seconds per request\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 2: Parallel (sync interface)\nprint(\"üöÄ Testing parallel collection...\")\n\n# Ensure sequential_time is available for comparison\nif 'sequential_time' not in locals():\n    print(\"‚ö†Ô∏è Sequential test not run yet - using estimated baseline\")\n    sequential_time = 1.0  # Fallback value\n\nwith AsyncCompatibleClient(credentials, max_concurrent=4) as client:\n    start_time = time.time()\n    \n    # Mock the client's collect_data method for testing\n    if DEMO_MODE:\n        original_method = client.collect_data\n        def mock_client_collect_data(reporting_period, rssd_id, series=\"call\", **kwargs):\n            return mock_collect_data(\n                session=basic_connection.session,\n                creds=credentials,\n                reporting_period=reporting_period,\n                rssd_id=rssd_id,\n                series=series,\n                **kwargs\n            )\n        client.collect_data = mock_client_collect_data\n    \n    try:\n        parallel_results = client.collect_data_parallel(\n            reporting_period=PERFORMANCE_PERIOD,\n            rssd_ids=PERFORMANCE_BANKS,\n            series=\"call\"\n        )\n        \n        parallel_time = time.time() - start_time\n        performance_results['Parallel'] = parallel_time\n        \n        print(f\"‚úÖ Parallel: {parallel_time:.2f} seconds for {len(PERFORMANCE_BANKS)} requests\")\n        print(f\"   Average: {parallel_time/len(PERFORMANCE_BANKS):.2f} seconds per request\")\n        \n        # Only calculate speedup if we have sequential_time\n        if 'sequential_time' in locals() and sequential_time > 0:\n            speedup = sequential_time / parallel_time\n            print(f\"   Speedup: {speedup:.1f}x faster than sequential\")\n        else:\n            print(\"   (Sequential time not available for comparison)\")\n        \n    except Exception as e:\n        print(f\"‚ùå Parallel test failed: {e}\")\n        performance_results['Parallel'] = float('inf')\n    \n    finally:\n        # Restore original method\n        if DEMO_MODE and 'original_method' in locals():\n            client.collect_data = original_method"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test 3: Pure async (for comparison)\nprint(\"‚ö° Testing pure async collection...\")\n\n# Ensure sequential_time is available for comparison\nif 'sequential_time' not in locals():\n    print(\"‚ö†Ô∏è Sequential test not run yet - using estimated baseline\")\n    sequential_time = 1.0  # Fallback value\n\nasync def test_async_performance():\n    async with AsyncCompatibleClient(\n        credentials, \n        max_concurrent=5,\n        rate_limit=20.0  # 20 requests per second\n    ) as client:\n        \n        start_time = time.time()\n        \n        # Create async tasks\n        tasks = []\n        for rssd_id in PERFORMANCE_BANKS:\n            if DEMO_MODE:\n                # Create mock async task\n                async def mock_async(rssd_id=rssd_id):\n                    await asyncio.sleep(random.uniform(0.1, 0.3))\n                    return mock_collect_data(\n                        session=basic_connection.session,\n                        creds=credentials,\n                        reporting_period=PERFORMANCE_PERIOD,\n                        rssd_id=rssd_id,\n                        series=\"call\"\n                    )\n                task = mock_async()\n            else:\n                task = client.collect_data_async(\n                    reporting_period=PERFORMANCE_PERIOD,\n                    rssd_id=rssd_id,\n                    series=\"call\"\n                )\n            tasks.append(task)\n        \n        # Execute all tasks concurrently\n        async_results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        async_time = time.time() - start_time\n        \n        return async_time, async_results\n\ntry:\n    async_time, async_results = await test_async_performance()\n    performance_results['Async'] = async_time\n    \n    print(f\"‚úÖ Async: {async_time:.2f} seconds for {len(PERFORMANCE_BANKS)} requests\")\n    print(f\"   Average: {async_time/len(PERFORMANCE_BANKS):.2f} seconds per request\")\n    \n    # Only calculate speedup if we have sequential_time\n    if 'sequential_time' in locals() and sequential_time > 0:\n        speedup = sequential_time / async_time\n        print(f\"   Speedup: {speedup:.1f}x faster than sequential\")\n    else:\n        print(\"   (Sequential time not available for comparison)\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Async test failed: {e}\")\n    performance_results['Async'] = float('inf')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize performance comparison\nprint(\"üìä Performance Visualization\")\n\n# Create performance comparison chart\nvalid_results = {k: v for k, v in performance_results.items() if v != float('inf')}\n\nif len(valid_results) > 1:\n    plt.figure(figsize=(10, 6))\n    \n    methods = list(valid_results.keys())\n    times = list(valid_results.values())\n    \n    # Bar chart\n    bars = plt.bar(methods, times, color=['#ff9999', '#66b3ff', '#99ff99'][:len(methods)])\n    \n    # Add value labels on bars\n    for bar, time_val in zip(bars, times):\n        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n                f'{time_val:.2f}s', ha='center', va='bottom')\n    \n    plt.title('Performance Comparison: Data Collection Methods')\n    plt.ylabel('Time (seconds)')\n    plt.xlabel('Collection Method')\n    \n    # Add speedup annotations\n    if 'Sequential' in valid_results:\n        baseline = valid_results['Sequential']\n        for i, (method, time_val) in enumerate(valid_results.items()):\n            if method != 'Sequential':\n                speedup = baseline / time_val\n                plt.text(i, time_val/2, f'{speedup:.1f}x\\nfaster', \n                        ha='center', va='center', fontweight='bold')\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # Summary table\n    print(\"\\nüìà Performance Summary:\")\n    num_requests = len(PERFORMANCE_BANKS)  # Use actual number of banks tested\n    perf_df = pd.DataFrame([\n        {\n            'Method': method,\n            'Total Time (s)': f\"{time_val:.2f}\",\n            'Avg per Request (s)': f\"{time_val/num_requests:.3f}\",\n            'Speedup': f\"{valid_results['Sequential']/time_val:.1f}x\" if 'Sequential' in valid_results else 'N/A'\n        }\n        for method, time_val in valid_results.items()\n    ])\n    \n    display(perf_df)\nelse:\n    print(\"‚ùå Not enough valid results for comparison\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Error Handling and Validation\n",
    "\n",
    "The library provides comprehensive error handling and data validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling examples\n",
    "print(\"üõ°Ô∏è Error Handling Examples\")\n",
    "\n",
    "# 1. Invalid RSSD ID\n",
    "print(\"\\n1. Testing invalid RSSD ID...\")\n",
    "try:\n",
    "    invalid_data = collect_data(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        reporting_period=\"2023-12-31\",\n",
    "        rssd_id=\"invalid_id\",  # Invalid: not numeric\n",
    "        series=\"call\"\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(f\"‚úÖ Caught ValidationError: {e}\")\n",
    "except ValueError as e:  # Legacy mode\n",
    "    print(f\"‚úÖ Caught ValueError (legacy mode): {e}\")\n",
    "\n",
    "# 2. Empty RSSD ID\n",
    "print(\"\\n2. Testing empty RSSD ID...\")\n",
    "try:\n",
    "    empty_data = collect_data(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        reporting_period=\"2023-12-31\",\n",
    "        rssd_id=\"\",  # Empty\n",
    "        series=\"call\"\n",
    "    )\n",
    "except (ValidationError, ValueError) as e:\n",
    "    print(f\"‚úÖ Caught error for empty RSSD: {e}\")\n",
    "\n",
    "# 3. Invalid credentials\n",
    "print(\"\\n3. Testing invalid credentials...\")\n",
    "try:\n",
    "    bad_creds = WebserviceCredentials(\"bad_user\", \"bad_pass\")\n",
    "    print(f\"Created bad credentials (masked): {bad_creds}\")\n",
    "    \n",
    "    # Note: This would fail on actual FFIEC service, but our mock accepts any creds\n",
    "    if not DEMO_MODE:\n",
    "        bad_data = collect_data(\n",
    "            session=basic_connection.session,\n",
    "            creds=bad_creds,\n",
    "            reporting_period=\"2023-12-31\",\n",
    "            rssd_id=\"480228\",\n",
    "            series=\"call\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è In demo mode - mock server accepts any credentials\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚úÖ Caught authentication error: {e}\")\n",
    "\n",
    "# 4. Invalid output type\n",
    "print(\"\\n4. Testing invalid output type...\")\n",
    "try:\n",
    "    bad_output = collect_data(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        reporting_period=\"2023-12-31\",\n",
    "        rssd_id=\"480228\",\n",
    "        series=\"call\",\n",
    "        output_type=\"invalid_type\"  # Invalid output type\n",
    "    )\n",
    "except (ValidationError, ValueError) as e:\n",
    "    print(f\"‚úÖ Caught error for invalid output type: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legacy vs New Error Mode\n",
    "print(\"üîÑ Error Mode Comparison\")\n",
    "\n",
    "from ffiec_data_connect.config import use_legacy_errors, disable_legacy_mode, enable_legacy_mode\n",
    "\n",
    "print(f\"Current legacy mode: {use_legacy_errors()}\")\n",
    "\n",
    "# Test with new error mode\n",
    "print(\"\\nüìä Testing with new error mode...\")\n",
    "disable_legacy_mode()\n",
    "try:\n",
    "    collect_data(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        reporting_period=\"2023-12-31\",\n",
    "        rssd_id=\"abc123\",\n",
    "        series=\"call\"\n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(f\"‚úÖ New mode - ValidationError: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "    print(f\"   Field: {e.field}\")\n",
    "    print(f\"   Value: {e.value}\")\n",
    "\n",
    "# Test with legacy error mode\n",
    "print(\"\\nüîô Testing with legacy error mode...\")\n",
    "enable_legacy_mode()\n",
    "try:\n",
    "    collect_data(\n",
    "        session=basic_connection.session,\n",
    "        creds=credentials,\n",
    "        reporting_period=\"2023-12-31\",\n",
    "        rssd_id=\"abc123\",\n",
    "        series=\"call\"\n",
    "    )\n",
    "except ValueError as e:\n",
    "    print(f\"‚úÖ Legacy mode - ValueError: {e}\")\n",
    "    print(f\"   Error type: {type(e).__name__}\")\n",
    "\n",
    "print(f\"\\nFinal legacy mode: {use_legacy_errors()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Data Visualization Examples\n",
    "\n",
    "Create visualizations from the collected financial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations from the data\n",
    "print(\"üìä Creating Data Visualizations\")\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Use the pandas DataFrame for plotting\n",
    "if len(df_pandas) > 0 and 'value' in df_pandas.columns:\n",
    "    \n",
    "    # 1. Bank comparison chart\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Subplot 1: Total Assets by Bank\n",
    "    plt.subplot(2, 2, 1)\n",
    "    asset_data = df_pandas[df_pandas['metric'] == 'Total Assets']\n",
    "    if len(asset_data) > 0:\n",
    "        sns.barplot(data=asset_data, x='rssd_id', y='value', hue='reporting_period')\n",
    "        plt.title('Total Assets by Bank and Period')\n",
    "        plt.ylabel('Assets ($ millions)')\n",
    "        plt.xlabel('Bank RSSD ID')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title='Reporting Period', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Subplot 2: ROA Trend\n",
    "    plt.subplot(2, 2, 2)\n",
    "    roa_data = df_pandas[df_pandas['metric'] == 'ROA']\n",
    "    if len(roa_data) > 0:\n",
    "        for bank in roa_data['rssd_id'].unique():\n",
    "            bank_roa = roa_data[roa_data['rssd_id'] == bank]\n",
    "            plt.plot(bank_roa['reporting_period'], bank_roa['value'], \n",
    "                    marker='o', label=f'Bank {bank}')\n",
    "        plt.title('Return on Assets (ROA) Trend')\n",
    "        plt.ylabel('ROA (%)')\n",
    "        plt.xlabel('Reporting Period')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Subplot 3: Net Income Distribution\n",
    "    plt.subplot(2, 2, 3)\n",
    "    income_data = df_pandas[df_pandas['metric'] == 'Net Income']\n",
    "    if len(income_data) > 0:\n",
    "        sns.boxplot(data=income_data, x='rssd_id', y='value')\n",
    "        plt.title('Net Income Distribution by Bank')\n",
    "        plt.ylabel('Net Income ($ millions)')\n",
    "        plt.xlabel('Bank RSSD ID')\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    # Subplot 4: Correlation heatmap\n",
    "    plt.subplot(2, 2, 4)\n",
    "    # Pivot data for correlation analysis\n",
    "    pivot_data = df_pandas.pivot_table(\n",
    "        index=['rssd_id', 'reporting_period'], \n",
    "        columns='metric', \n",
    "        values='value', \n",
    "        aggfunc='mean'\n",
    "    ).reset_index()\n",
    "    \n",
    "    if len(pivot_data.columns) > 3:  # At least some metrics\n",
    "        numeric_cols = pivot_data.select_dtypes(include=[np.number]).columns\n",
    "        if len(numeric_cols) > 1:\n",
    "            corr_matrix = pivot_data[numeric_cols].corr()\n",
    "            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "                       square=True, fmt='.2f')\n",
    "            plt.title('Correlation Matrix of Financial Metrics')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save the visualization\n",
    "    plt.savefig('ffiec_data_visualization.png', dpi=300, bbox_inches='tight')\n",
    "    print(\"‚úÖ Visualization saved as 'ffiec_data_visualization.png'\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup and Summary\n",
    "\n",
    "Clean up resources and summarize what we've accomplished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources\n",
    "print(\"üßπ Cleaning up resources...\")\n",
    "\n",
    "# Close connections\n",
    "if 'basic_connection' in locals():\n",
    "    basic_connection.close()\n",
    "    print(\"‚úÖ Closed basic connection\")\n",
    "\n",
    "if 'async_client' in locals():\n",
    "    async_client.close()\n",
    "    print(\"‚úÖ Closed async client\")\n",
    "\n",
    "# Stop mock server if running\n",
    "if DEMO_MODE and 'mock_server' in locals():\n",
    "    mock_server.stop()\n",
    "    print(\"‚úÖ Stopped mock server\")\n",
    "\n",
    "# Clear SOAP cache\n",
    "from ffiec_data_connect import clear_soap_cache, get_cache_stats\n",
    "\n",
    "print(f\"\\nSOAP cache stats before cleanup: {get_cache_stats()}\")\n",
    "clear_soap_cache()\n",
    "print(f\"SOAP cache stats after cleanup: {get_cache_stats()}\")\n",
    "\n",
    "print(\"\\nüéâ Cleanup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of demonstration\n",
    "print(\"üìã DEMONSTRATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nüîç What we demonstrated:\")\n",
    "print(\"  ‚úÖ Basic synchronous data collection\")\n",
    "print(\"  ‚úÖ Async data collection with rate limiting\")\n",
    "print(\"  ‚úÖ Parallel processing with sync interface\")\n",
    "print(\"  ‚úÖ Pandas DataFrame creation and analysis\")\n",
    "print(\"  ‚úÖ Polars DataFrame operations and performance\")\n",
    "print(\"  ‚úÖ Data export to multiple formats (CSV, Excel, Parquet, JSON)\")\n",
    "print(\"  ‚úÖ Performance comparison of different approaches\")\n",
    "print(\"  ‚úÖ Comprehensive error handling and validation\")\n",
    "print(\"  ‚úÖ Data visualization with matplotlib/seaborn\")\n",
    "print(\"  ‚úÖ Resource management and cleanup\")\n",
    "\n",
    "print(\"\\nüíæ Files created:\")\n",
    "created_files = [\n",
    "    'ffiec_data_pandas.csv',\n",
    "    'ffiec_data_pandas.xlsx', \n",
    "    'ffiec_data_pandas.parquet',\n",
    "    'ffiec_data_polars.csv',\n",
    "    'ffiec_data_polars.parquet',\n",
    "    'ffiec_data_polars.json',\n",
    "    'ffiec_data_visualization.png'\n",
    "]\n",
    "\n",
    "total_size = 0\n",
    "for file in created_files:\n",
    "    if os.path.exists(file):\n",
    "        size_kb = os.path.getsize(file) / 1024\n",
    "        total_size += size_kb\n",
    "        print(f\"  üìÑ {file}: {size_kb:.1f} KB\")\n",
    "\n",
    "print(f\"\\nüìä Total files size: {total_size:.1f} KB\")\n",
    "\n",
    "if 'performance_results' in locals():\n",
    "    print(\"\\n‚ö° Performance highlights:\")\n",
    "    for method, time_val in performance_results.items():\n",
    "        if time_val != float('inf'):\n",
    "            print(f\"  {method}: {time_val:.2f} seconds\")\n",
    "\n",
    "print(\"\\nüöÄ Ready for production use!\")\n",
    "print(\"\\nüí° Next steps:\")\n",
    "print(\"  1. Set up your FFIEC credentials as environment variables\")\n",
    "print(\"  2. Use AsyncCompatibleClient for better performance\")\n",
    "print(\"  3. Choose Polars for large datasets, Pandas for smaller ones\")\n",
    "print(\"  4. Implement proper error handling in your applications\")\n",
    "print(\"  5. Use context managers for automatic resource cleanup\")\n",
    "\n",
    "print(\"\\nüìö Documentation: https://ffiec-data-connect.readthedocs.io/\")\n",
    "print(\"üêõ Report issues: https://github.com/call-report/ffiec-data-connect/issues\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}